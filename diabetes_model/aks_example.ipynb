{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy a model to a secure AKS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Connect to Azure Machine Learning Workspace\n",
        "\n",
        "## 1.1. Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "install",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%pip install azure.ai.ml --extra-index-url  https://azuremlsdktestpypi.azureedge.net/sdk-cli-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1675767232663
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Model, Environment, KubernetesOnlineEndpoint, KubernetesOnlineDeployment, CodeConfiguration\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.entities._deployment.resource_requirements_settings import ResourceRequirementsSettings\n",
        "from azure.ai.ml.entities._deployment.container_resource_settings import ResourceSettings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2. Configure workspace details and get a handle to the workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1675767232865
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Enter details of your AML workspace\n",
        "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "resource_group = \"<RESOURCE_GROUP>\"\n",
        "workspace = \"<AML_WORKSPACE_NAME>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1675767234639
        },
        "name": "ml_client"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Create a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675767944582
        },
        "name": "file_model"
      },
      "outputs": [],
      "source": [
        "model = Model(path=\"./model/sklearn_regression_model.pkl\")\n",
        "\n",
        "ml_client.models.create_or_update(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 3. Create an inference environment for the model\n",
        "\n",
        "## Environment\n",
        "\n",
        "[Note about no-code-deployment](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models-online-endpoints?tabs=cli) : Azure Machine Learning performs dynamic installation of packages when deploying MLflow models with no-code deployment. As a consequence, deploying MLflow models to online endpoints with no-code deployment in a private network without egress connectivity is not supported by the moment.\n",
        "\n",
        "This means we have to provide an environment and a scoring files for secured infrastructure.\n",
        "\n",
        "All curated environment are part of mcr.microsoft.com and most customers do not want to allow public network trafic from/to their inference endpoint.\n",
        "\n",
        "This means you have to create a custom environment that will be saved in your private container registry. You have 2 ways to do this :\n",
        "- Define a custom environment within AML and let the image-builder cluster build it and save it in ACR for you. The cluster will require access to the source you are using.\n",
        "- Use your own platform (a side VM ?) to create and push your docker image to the ACR, and then register it to AML.\n",
        "\n",
        "### Build a custom environment within AML\n",
        "\n",
        "Network prerequisite : image-builder cluster (within training subnet) can to reach out to mcr.microsoft.com to retrieve curated image as a base image to build the custom one that will be saved into private ACR. (This is already implemented as part as the terraform code).\n",
        "\n",
        "The following command will :\n",
        "- Define the environment \n",
        "- Register the environment\n",
        "- Build it on imabe_builder cluster (because we defined this cluster as default during installation) \n",
        "- Save the environment in Azure contrainer registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675767963474
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "env = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/curated/minimal-ubuntu18.04-py37-cpu-inference:51\",\n",
        "    conda_file=\"environment/conda.yml\",\n",
        "    name=\"my_custom_inference_env\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 4. Setup a Kubernetes online endpoint\n",
        "\n",
        "This takes around 2mins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"k8s-endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = KubernetesOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    compute=\"<COMPUTE_NAME>\",\n",
        "    auth_mode=\"key\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675702110431
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"k8s-endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = KubernetesOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    compute=\"aks-inference\",\n",
        "    auth_mode=\"key\",\n",
        ")\n",
        "\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 5. Create the online deployment\n",
        "\n",
        "This takes around 2mins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675768226456
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "deployment = KubernetesOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    environment=env,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"src\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    instance_count=1,\n",
        "    resources=ResourceRequirementsSettings(\n",
        "        requests=ResourceSettings(\n",
        "            cpu=\"100m\",\n",
        "            memory=\"0.5Gi\",\n",
        "        ),\n",
        "    )      \n",
        ")\n",
        "\n",
        "ml_client.begin_create_or_update(deployment).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 6. Test the endpoint with sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675779662260
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "data = {}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "url = 'http://10.42.0.91/aml/api/v1/endpoint/k8s-endpoint-02061646309278/score'\n",
        "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
        "api_key = 'mRuLigIIk5gclRmgBblIv3ePXARcjYYL'\n",
        "if not api_key:\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'blue' }\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Troubleshooting commodities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675759735855
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ml_client.online_deployments.get_logs(\n",
        "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "description": {
      "description": "Create model from local files, cloud files, Runs"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
